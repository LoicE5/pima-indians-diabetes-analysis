{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Notre approche pour la résolution de ce problème consiste en une série d’exécution de différents algorithmes vus en cours, soit :\n",
    "\n",
    "- K plus proches voisins\n",
    "- Arbre de decision\n",
    "- Classification naïve bayésienne\n",
    "- Perceptron\n",
    "- Adaline\n",
    "- Réseau de neurones\n",
    "- K-means\n",
    "- Classification hiérarchique\n",
    "\n",
    "Via une fonction permettant de déterminer la précision d’un modèle, en se basant sur un jeu de données d’entraînement et un jeu de données de test, nous procéderons en trois phases :\n",
    "\n",
    "1. Implémentation des algorithmes avec leurs paramètres par défaut. Observation des performances. Cette phase sert à avoir une idée \"de prime abord\" de quels algorithmes seront à conserver par la suite.\n",
    "2. Essais de ces mêmes algorithmes avec des paramètres différents. Sélection du jeu de paramètres le plus adéquat maximisant la précision de l’algorithme. Élimination des algorithmes les moins performants.\n",
    "3. Création d’un ensemble de 10 instances du dataset fourni, avec un shuffling aléatoire différent. Création des vecteurs de données et de résultat, et exécution sur les algorithmes les plus précis filtrés en 2.\n",
    "\n",
    "À l’issue de cette troisième phase, le meilleur algorithme sera celui qui obtiendra le meilleur score de précision.\n",
    "\n",
    "> La plupart des algorithmes utilisés ici sont des classes provenant de la librairie Python Scikit-Learn. En cas d'usage d'une autre classe et, plus généralement, d'un code provenant d'une source tierce (internet, camarade), sa provenance sera systématiquement indiquée en commentaire.\n",
    "\n",
    "# Dépendances\n",
    "\n",
    "- python >= 3.11\n",
    "- numpy >= 1.23.4\n",
    "- pandas >= 1.5.2\n",
    "- scikit-learn >= 1.1.3\n",
    "- sklearn-hierarchical-classification >= 1.3.2\n",
    "\n",
    "# Phase 1 : Essais avec l'ensemble des algorithmes non-paramétrés\n",
    "\n",
    "## Importation du dataset, création des vecteurs X et y d'entraînement et de test\n",
    "\n",
    "On récupère tout d'abord le jeu de données en .csv sous la forme d'un DataFrame, qu'on scinde avec un échantillon de 20% aléatoire pour les tests, et le reste pour l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Source : https://datagy.io/pandas-shuffle-dataframe/#:~:text=One%20of%20the%20easiest%20ways,Dataframe%2C%20in%20a%20random%20order.\n",
    "df = pd.read_csv(\"./diabetes.csv\").sample(\n",
    "    frac = 1,\n",
    "    random_state=1\n",
    ").reset_index()\n",
    "\n",
    "y = df['Outcome']\n",
    "X = df.drop('Outcome', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'une fonction évaluant la précision de chaque algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_hierarchical_classification.classifier import HierarchicalClassifier\n",
    "\n",
    "from numpy import ndarray\n",
    "\n",
    "def calculate_classifier_accuracy(\n",
    "    X_train:ndarray,\n",
    "    X_test:ndarray,\n",
    "    y_train:ndarray,\n",
    "    y_test:ndarray,\n",
    "    classifier:KNeighborsClassifier|DecisionTreeClassifier|GaussianNB|Perceptron|MLPClassifier|KMeans|HierarchicalClassifier,\n",
    "    return_confusion_matrix:bool=False\n",
    "):\n",
    "    classifier.fit(X_train,y_train)\n",
    "\n",
    "    predicted = classifier.predict(X_test)\n",
    "\n",
    "    accuracy = [True if predicted[i] == y_test[i] else False for i in range(len(predicted))]\n",
    "    accuracy_stats = {\n",
    "        \"right\": len([i for i in accuracy if i]),\n",
    "        \"wrong\": len([i for i in accuracy if not i])\n",
    "    }\n",
    "    accuracy_stats[\"percentage\"] = round((accuracy_stats[\"right\"]/len(accuracy))*100,2)\n",
    "\n",
    "    if return_confusion_matrix:\n",
    "        accuracy_stats[\"confusion_matrix\"] = {\n",
    "        \"true_positive\": len([1 for i in range(len(predicted)) if (predicted[i] == y_test[i] and predicted[i] == 1)]),\n",
    "        \"true_negative\": len([1 for i in range(len(predicted)) if (predicted[i] == y_test[i] and predicted[i] == 0)]),\n",
    "        \"false_positive\":len([1 for i in range(len(predicted)) if (predicted[i] != y_test[i] and predicted[i] == 1)]),\n",
    "        \"false_negative\":len([1 for i in range(len(predicted)) if (predicted[i] != y_test[i] and predicted[i] == 0)])\n",
    "    }\n",
    "\n",
    "    return accuracy_stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation des algorithmes\n",
    "\n",
    "### K plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 102, 'wrong': 52, 'percentage': 66.23}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, KNeighborsClassifier())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 109, 'wrong': 45, 'percentage': 70.78}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification naïve bayésienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 111, 'wrong': 43, 'percentage': 72.08}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, GaussianNB())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 54, 'wrong': 100, 'percentage': 35.06}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, Perceptron())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaline\n",
    "\n",
    "Pour cet algorithme, n'ayant pas trouvé d'équivalent sur sklearn, nous utilisons le code de M. Ajitesh Kumar, trouvable sur le site VitalFlux.com, à l'adresse : https://vitalflux.com/adaline-explained-with-python-example/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'right': 101, 'wrong': 53, 'percentage': 65.58}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Source : https://vitalflux.com/adaline-explained-with-python-example/\n",
    "class CustomAdaline:\n",
    "     \n",
    "    def __init__(self, n_iterations=100, random_state=1, learning_rate=0.01):\n",
    "        self.n_iterations = n_iterations\n",
    "        self.random_state = random_state\n",
    "        self.learning_rate = learning_rate\n",
    " \n",
    "    '''\n",
    "    Batch Gradient Descent\n",
    "     \n",
    "    1. Weights are updated considering all training examples.\n",
    "    2. Learning of weights can continue for multiple iterations\n",
    "    3. Learning rate needs to be defined\n",
    "    '''\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.coef_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        for _ in range(self.n_iterations):\n",
    "              activation_function_output = self.activation_function(self.net_input(X))\n",
    "              errors = y - activation_function_output\n",
    "              self.coef_[1:] = self.coef_[1:] + self.learning_rate*X.T.dot(errors)\n",
    "              self.coef_[0] = self.coef_[0] + self.learning_rate*errors.sum()\n",
    "     \n",
    "    '''\n",
    "    Net Input is sum of weighted input signals\n",
    "    '''\n",
    "    def net_input(self, X):\n",
    "            weighted_sum = np.dot(X, self.coef_[1:]) + self.coef_[0]\n",
    "            return weighted_sum\n",
    "     \n",
    "    '''\n",
    "    Activation function is fed the net input. As the activation function is\n",
    "    an identity function, the output from activation function is same as the\n",
    "    input to the function.\n",
    "    '''\n",
    "    def activation_function(self, X):\n",
    "            return X\n",
    "     \n",
    "    '''\n",
    "    Prediction is made on the basis of output of activation function\n",
    "    '''\n",
    "    def predict(self, X):\n",
    "        return np.where(self.activation_function(self.net_input(X)) >= 0.0, 1, 0)\n",
    "     \n",
    "    '''\n",
    "    Model score is calculated based on comparison of\n",
    "    expected value and predicted value\n",
    "    '''\n",
    "    def score(self, X, y):\n",
    "        misclassified_data_count = 0\n",
    "        for xi, target in zip(X, y):\n",
    "            output = self.predict(xi)\n",
    "            if(target != output):\n",
    "                misclassified_data_count += 1\n",
    "        total_data_count = len(X)\n",
    "        self.score_ = (total_data_count - misclassified_data_count)/total_data_count\n",
    "        return self.score_\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, CustomAdaline())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 102, 'wrong': 52, 'percentage': 66.23}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, MLPClassifier())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 17, 'wrong': 137, 'percentage': 11.04}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, KMeans())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification hiérarchique\n",
    "\n",
    "Cet algorithme de classification hiérarchique ne provient pas de Scikit-Learn à proprement parler, mais d'une librairie nommée `sklearn-hierarchical-classification`, proposant une classe de classification hiérarchique dérivée des algorithmes de Scikit-Learn. Cette librairie est disponible via pip et dispose d'un lien [PyPi](https://pypi.org/project/sklearn-hierarchical-classification/). Elle est maintenue par [Globality](https://www.globality.com/en-us)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 117, 'wrong': 37, 'percentage': 75.97}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn_hierarchical_classification.classifier import HierarchicalClassifier\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, HierarchicalClassifier())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient donc les résultats suivants :\n",
    "\n",
    "| Algorithme                      | Précision | Nombre de bonnes prédictions | Nombre de fausses prédictions |\n",
    "|---------------------------------|-----------|------------------------------|-------------------------------|\n",
    "| K plus proches voisins          | 66%       | 114                          | 52                            |\n",
    "| Arbre de decision               | ≈72%*     | ≈110*                        | ≈44*                          |\n",
    "| Classification naïve bayésienne | 72%       | 111                          | 43                            |\n",
    "| Perceptron                      | 35%       | 54                           | 100                           |\n",
    "| Adaline                         | 66%       | 101                          | 53                            |\n",
    "| Réseau de neurones              | ≈61%*     | ≈103*                        | ≈51*                          |\n",
    "| K-means                         | 14%       | 17                           | 137                           |\n",
    "| Classification hiérarchique     | 76%       | 117                          | 37                            |\n",
    "\n",
    "<br>\n",
    "\n",
    "> \\* La génération de l'arbre de décision implique une certaine aléatoirité des résultats, cependant avec une précision toujours contenue entre 70.0 et 74.5.\n",
    "<br>\n",
    "\n",
    "> \\* On observe une situation similaire avec le réseau de neurones, avec une précision oscillant entre 58.0 et 72.0.\n",
    "\n",
    "# Phase 2 : Paramétrage des algorithmes et élimination\n",
    "\n",
    "Notre objectif ici va être de rechercher, par itérations et essais successifs, les paramètres d'entrée de chaque algorithme donnant les meilleurs résultats, en terme de précision. Chaque algorithme se voit associé à un court paragraphe d'explication justifiant les choix de paramètres qui lui sont afférents.\n",
    "\n",
    "### K plus proches voisins\n",
    "\n",
    "Passer le nombre de plus proches voisins à considérer de 5 par défaut à 20 a permis d'augmenter le taux de précision vers ≈68%. L'augmentation de cette valeur au delà de 20 réduisait la précision, et en deçà la stabilisait à son niveau précédent.\n",
    "\n",
    "Par défaut, chaque voisin est équipondéré lorsqu'on cherche à définir l'étiquette du nouveau point. En changeant la valeur de `weights`de `uniform` à `distance`, on utilise ainsi un système de pondération où plus le voisin est proche, plus il va être pondéré, permettant d'atteindre un taux de précision de ≈69.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 107, 'wrong': 47, 'percentage': 69.48}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsClassifier(\n",
    "    n_neighbors=20,\n",
    "    weights=\"distance\"\n",
    ")\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, kn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision\n",
    "\n",
    "La modification des paramètres de la classe, notamment du `criterion` (utilisant l'impureté de Gini par défaut) et du `splitter` (stratégie de division de chaque noeud, pouvant être \"best\" (la meilleure stratégie est déterminée par l'algorithme et appliquée) ou \"random\" (une stratégie de division de noeud aléatoire est appliquée)), n'ont pas permis d'améliorer les résultats. Toute tentative de paramétrage a mené l'algorithme a produire des résultats en deçà de 10 points ou plus de la moyenne de sa précision précédente.\n",
    "\n",
    "La non-consistence des prédictions effecutées par cet algorithme (malgré un taux de bonnes prédictions élevé) ainsi que, par extension, la variabilité du résultat fourni, nous conforte dans le choix de son élimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 112, 'wrong': 42, 'percentage': 72.73}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, dt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification naïve bayésienne\n",
    "\n",
    "Cet algorithme présente deux paramètres :\n",
    "\n",
    "- priors : Une liste de probabilités pour chaque classe. Cela implique de connaître ces dernières, celles-ci remplaçant celles calculées par l'algorithme. Cette valeur n'est pas définie par défaut.\n",
    "- var_smotthing : Une valeur (inférieure à 1, par défaut à 1e-9) qui correspond à l'amplitude de la moyenne considérée dans la courbe de Gauss. Modifier cette valeur permet d'agrandir le champ adjacent à la moyenne et d'inclure plus de points dans la classification *([source](https://stackoverflow.com/questions/58046129/can-someone-give-a-good-math-stats-explanation-as-to-what-the-parameter-var-smoo))*.\n",
    "\n",
    "Nous avons trouvé que toute valeur s'éloignant de la valeur par défaut de var_smoothing avait un impact nul, sinon négatif sur les performances de l'algorithme. Dans ce cas de figure, il s'agit également d'un algorithme pour lequel nous ne modifierons pas les paramètres dans une perspective d'amélioration de précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 111, 'wrong': 43, 'percentage': 72.08}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB(\n",
    "    var_smoothing=1e-9\n",
    ")\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, gnb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "Il a été possible d'augmenter la précision du perceptron en jouant sur deux paramètres :\n",
    "- `penalty` : Un type de régularisation permettant d'éviter une trop grande variabilité du modèle en terme de prédiction. Cette valeur peut être soit de \"l1\" (utilisant la [norme de manhattan](https://en.wikipedia.org/wiki/Taxicab_geometry)), \"l2\" (utilisant la norme euclidienne) ou \"elasticnet\" (une combinaison des deux précédentes). Par défaut, la pénalité est à None.\n",
    "  L'utilité de ce paramètre peut être illustré par ces images d'exemple :\n",
    "\n",
    "| Sans régularisation                                                                                | Avec régularisation                                                                                |\n",
    "|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|\n",
    "| <img src=\"https://github.com/christianversloot/machine-learning-articles/raw/main/images/poly_large.png\" width=\"300px\"> | <img src=\"https://github.com/christianversloot/machine-learning-articles/raw/main/images/poly_small.png\" width=\"300px\"> |\n",
    "\n",
    "- `l1_ratio` : Lorsque `penalty` est défini sur \"elasticnet\", spécifie le pourcentage de l1 qui doit être appliqué par rapport à l2.\n",
    "\n",
    "\n",
    "Nos tests ont montré que : \n",
    "- L'ajout d'une pénalité seule impliquait une baisse de environ 1% de la précision du modèle\n",
    "- Cependant, l'ajout d'un l1_ratio a permis d'augmenter considérablement la précision du perceptron, lui octroyant près du double de sa précision d'origine. Toute valeur <= 0.4 n'a pas d'impact significatif. Le pic (64.94%) de précision est atteint à 0.5. Enfin, cette dernière décroît graduellement au fur et à mesure de l'augmentation du ratio.\n",
    "\n",
    "La modification de ces paramètres ont permis de transformer le perceptron d'un algorithme peu intéressant à un algorithme offrant des performances honorables.\n",
    "\n",
    "Les informations (ainsi que les images) que nous avons utilisé pour comprendre la régularisation proviennent d'un [article de M. Christian Versloot sur GitHub](https://github.com/christianversloot/machine-learning-articles/blob/main/what-are-l1-l2-and-elastic-net-regularization-in-neural-networks.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 100, 'wrong': 54, 'percentage': 64.94}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcptr = Perceptron(\n",
    "    penalty=\"elasticnet\",\n",
    "    l1_ratio=0.5\n",
    ")\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, pcptr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaline\n",
    "\n",
    "La modification d'aucun paramètre du code proposé par M. Ajitesh Kumar n'a permis d'impacter le résultat de l'algorithme, positivement ou négativement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'right': 101, 'wrong': 53, 'percentage': 65.58}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adl = CustomAdaline()\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, adl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau de neurones\n",
    "\n",
    "La classe MLPClassifier de Scikit-Learn présente un grand nombre de paramètres. Parmi eux se trouvent notamment :\n",
    "- hidden_layer_size : La taille de la couche cachée (par défaut à 100, les tests ont montré une absence d'amélioration en modifiant cette valeur)\n",
    "- activation : La fonction d'activation de la couche cachée (\"identity\", \"logistic\", \"tanh\", \"relu\", par défaut à \"relu\"). Nos tests ont permis de déterminer que \"logistic\" permettait de diminuer la variabilité des résultats, et de conserver une précision haute par rapport aux extrêmes les plus bas précédents.\n",
    "- solver : L'algorithme qui va déterminer la répartition des poids entre les couches du réseau. On a 3 possibilités :\n",
    "  - \"lbfgs\" : fonctionne mieux sur des datasets larges, repose sur un principe de [méthodes quasi-Newton](https://fr.wikipedia.org/wiki/M%C3%A9thode_quasi-Newton).\n",
    "  - \"sgd\" : Algorithme de descente de gradient standard\n",
    "  - \"adam\" (par défaut) : Algorithme de descente de gradient amélioré\n",
    "  L'utilisation d'un autre algorithme que \"adam\" n'a pas eu d'impact positif constaté sur les performances.\n",
    "\n",
    "La classe MLPClassifier présente également d'autre paramètres afférents à, par exemple, certains solveurs spécifiques comme \"adam\" ou \"sgd\". Cependant, malgré l'exhaustivité des paramètres proposés, il ne nous apparaît pas pertinent d'utiliser un réseau de neurones pour cette tâche, au vu de la variabilité de sa précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'right': 101, 'wrong': 53, 'percentage': 65.58}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc = MLPClassifier(\n",
    "    activation=\"logistic\"\n",
    ")\n",
    "\n",
    "calculate_classifier_accuracy(X_train, X_test, y_train, y_test, mlpc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
